{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85507c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils import create_train_test_group\n",
    "\n",
    "# update mroRnnDataset with better performance\n",
    "from utils import mroRnnDataset as mroRnnDataset\n",
    "from utils import collate_fn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices available: {num_gpus}\")\n",
    "    # Select a specific GPU (e.g., GPU 0)\n",
    "    device = torch.device(\"cuda:8\")  # Use \"cuda:1\" for GPU 1, etc.\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA is not available, using CPU\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# data preprocessing control parameter\n",
    "sample_frac = 1\n",
    "test_size = 0.1\n",
    "max_seq_length = 20\n",
    "batch_size = 4096\n",
    "num_workers = 16\n",
    "\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_auc = 0.0\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "best_epoch = float(\"inf\")\n",
    "counter = 0\n",
    "patience = 10\n",
    "\n",
    "time_window_leakage = 5\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Parameters for RNN Model\n",
    "rnn_type = \"GRU\"\n",
    "rnn_output_size = 64\n",
    "bidirectional = True\n",
    "# pooling_method value =  None, 'max', 'avg'\n",
    "# 'attention', 'multihead_attention'\n",
    "num_layers = 3\n",
    "pooling_method = \"attention\"\n",
    "num_heads = 4\n",
    "use_last_hidden = True\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "log_dir = \"./Out\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file_path = os.path.join(log_dir, f\"training_log_{timestamp}_test.csv\")\n",
    "\n",
    "pt_model_dir = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(pt_model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "model_save_path = os.path.join(pt_model_dir, f\"best_model_{timestamp}.pth\")\n",
    "pt_model_save_path = os.path.join(pt_model_dir, f\"best_model_{timestamp}.pt\")\n",
    "\n",
    "\n",
    "file_name = \"./Data/mro_daily_clean.csv\"\n",
    "# ---------------------------------------------------------\n",
    "data = pd.read_csv(file_name, index_col=0, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variable = [\n",
    "    \"hard_braking\",\n",
    "    \"hard_acceleration\",\n",
    "    \"speeding_sum\",\n",
    "    \"day_mileage\",\n",
    "    \"engn_size\",\n",
    "    \"est_hh_incm_prmr_cd\",\n",
    "    \"purchaser_age_at_tm_of_purch\",\n",
    "    \"tavg\",\n",
    "    \"random_avg_traffic\",\n",
    "]\n",
    "\n",
    "category_variable = [\n",
    "    \"gmqualty_model\",\n",
    "    \"umf_xref_finc_gbl_trim\",\n",
    "    \"input_indiv_gndr_prmr_cd\",\n",
    "]\n",
    "\n",
    "driver_navigation = [\n",
    "    \"id\",\n",
    "    \"yr_nbr\",\n",
    "    \"mth_nbr\",\n",
    "    \"week_nbr\",\n",
    "]\n",
    "\n",
    "mro = ['mro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d577203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[driver_navigation + continuous_variable + category_variable + mro]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby([\"id\", \"yr_nbr\", \"week_nbr\"]).agg(\n",
    "    {\n",
    "        \"mth_nbr\": \"first\",\n",
    "        \"mro\": \"max\",\n",
    "        \"hard_braking\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "        \"hard_acceleration\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "        \"speeding_sum\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "        \"day_mileage\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "        \"est_hh_incm_prmr_cd\": \"first\",\n",
    "        \"purchaser_age_at_tm_of_purch\": \"first\",\n",
    "        \"input_indiv_gndr_prmr_cd\": \"first\",\n",
    "        \"gmqualty_model\": \"first\",\n",
    "        \"umf_xref_finc_gbl_trim\": \"first\",\n",
    "        \"engn_size\": \"first\",\n",
    "        \"tavg\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "        \"random_avg_traffic\": [\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_columns(df: pd.DataFrame):\n",
    "    def clean_col(col):\n",
    "        if isinstance(col, tuple):\n",
    "            col_name, agg_func = col\n",
    "            agg_func = agg_func.strip()\n",
    "            if col_name in mro and agg_func == \"max\":\n",
    "                return \"mro\"\n",
    "            if agg_func in (\"first\", \"\"):\n",
    "                return col_name\n",
    "            return f\"{col_name}_{agg_func}\"\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    df.columns = [clean_col(col) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1535c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = flatten_columns(data)\n",
    "data.fillna(0, inplace=True)\n",
    "data = data.drop([\"yr_nbr\", \"week_nbr\", \"mth_nbr\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_need_std = [\n",
    "    item\n",
    "    for item in data.columns.values.tolist()\n",
    "    if item not in (mro + [\"id\"] + category_variable)\n",
    "]\n",
    "\n",
    "col_need_encode = category_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data[col_need_std] = scaler.fit_transform(data[col_need_std])\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical = encoder.fit_transform(data[col_need_encode])\n",
    "\n",
    "category_counts = [\n",
    "    len(encoder.categories_[i]) for i, _ in enumerate(col_need_encode)\n",
    "]\n",
    "\n",
    "onehot_feature_names = []\n",
    "for col_idx, col in enumerate(col_need_encode):\n",
    "    num_categories = category_counts[col_idx]\n",
    "    onehot_feature_names.extend([f\"{col}_onehot_{i}\" for i in range(num_categories)])\n",
    "\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_categorical, index=data.index, columns=onehot_feature_names\n",
    ")\n",
    "data = pd.concat([data, encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_features = col_need_std + onehot_feature_names\n",
    "# col_rnn_origin = [\"id\"] + rnn_features + [\"mro\"]\n",
    "col_rnn_origin = [\"id\"] + rnn_features + mro\n",
    "data_rnn_origin = data[col_rnn_origin].copy()\n",
    "data_rnn_origin = create_train_test_group(\n",
    "    data_rnn_origin, sample_frac=sample_frac, test_size=test_size\n",
    ")\n",
    "# rnn_target = [\"mro\"]\n",
    "rnn_target = mro\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "\n",
    "train_data_set = mroRnnDataset(\n",
    "    data_rnn_origin=data_rnn_origin,\n",
    "    rnn_features=rnn_features,\n",
    "    rnn_target=rnn_target,\n",
    "    group=\"train\",\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "test_data_set = mroRnnDataset(\n",
    "    data_rnn_origin=data_rnn_origin,\n",
    "    rnn_features=rnn_features,\n",
    "    rnn_target=rnn_target,\n",
    "    group=\"test\",\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "\n",
    "# Example batch size\n",
    "train_dataloader = DataLoader(\n",
    "    train_data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "class RnnModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type: str,\n",
    "        input_size,\n",
    "        rnn_output_size,\n",
    "        output_size,\n",
    "        bidirectional: bool = False,\n",
    "        num_layers: int = 3,\n",
    "        pooling_method: str = \"attention\",  # value =  None, 'max', 'avg', 'attention', 'multihead_attention'\n",
    "        num_heads=4,\n",
    "        use_last_hidden: bool = True,\n",
    "    ):\n",
    "        super(RnnModel, self).__init__()\n",
    "        # bidirectional = False\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.embed_dim = rnn_output_size * num_directions\n",
    "        self.pooling_method = pooling_method\n",
    "        self.use_last_hidden = use_last_hidden\n",
    "\n",
    "        if rnn_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=input_size,\n",
    "                hidden_size=rnn_output_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=0.5,\n",
    "            )\n",
    "        elif rnn_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=input_size,\n",
    "                hidden_size=rnn_output_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=0.5,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "\n",
    "        if pooling_method == \"multihead_attention\":\n",
    "            self.attn = nn.MultiheadAttention(\n",
    "                embed_dim=self.embed_dim, num_heads=num_heads, batch_first=True\n",
    "            )\n",
    "        elif pooling_method == \"attention\":\n",
    "            self.attn = nn.MultiheadAttention(\n",
    "                embed_dim=self.embed_dim, num_heads=1, batch_first=True\n",
    "            )\n",
    "        elif pooling_method in [\"max\", \"avg\"]:\n",
    "            self.pool = getattr(nn, f\"Adaptive{pooling_method.capitalize()}Pool1d\")(1)\n",
    "        elif pooling_method is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported pooling_method: {pooling_method}\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, length: torch.Tensor):\n",
    "        # x (batch_size, seq_len, input_size)\n",
    "        # use pack_padded_sequence and pad_packed_sequence to deal with different length of x input\n",
    "        packed_x = pack_padded_sequence(\n",
    "            x, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, _ = self.rnn(packed_x)\n",
    "        rnn_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        # pooled = self.pool(rnn_out.transpose(1, 2)).squeeze(2)\n",
    "        # attended = self.attention(rnn_out)\n",
    "        if self.pooling_method is None:\n",
    "            if self.use_last_hidden:\n",
    "                idx = (length - 1).to(x.device)\n",
    "                batch_indices = torch.arange(x.size(0), device=x.device)\n",
    "                pooled = rnn_out[batch_indices, idx]  # (B, H)\n",
    "            else:\n",
    "                # use the average to of all outputs\n",
    "                pooled = rnn_out.mean(dim=1)  # (B, H)\n",
    "        elif self.pooling_method in [\"max\", \"avg\"]:\n",
    "            pooled = self.pool(rnn_out.transpose(1, 2)).squeeze(2)\n",
    "        elif self.pooling_method in [\"attention\", \"multihead_attention\"]:\n",
    "            # if self.pooling_method == \"multihead_attention\":\n",
    "            #     attn_out, _ = self.attn(rnn_out, rnn_out, rnn_out)\n",
    "            #     pooled = attn_out.mean(dim=1)\n",
    "            # else:\n",
    "            #     pooled = self.attn(rnn_out)\n",
    "            attn_output, _ = self.attn(rnn_out, rnn_out, rnn_out)\n",
    "            pooled = attn_output.mean(dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pooling_method\")\n",
    "\n",
    "        model_out = self.fc(pooled)\n",
    "        return model_out\n",
    "\n",
    "\n",
    "input_feature_size = len(rnn_features)\n",
    "output_size = len(rnn_target)\n",
    "\n",
    "model = RnnModel(\n",
    "    rnn_type=rnn_type,\n",
    "    input_size=input_feature_size,\n",
    "    rnn_output_size=rnn_output_size,\n",
    "    output_size=output_size,\n",
    "    bidirectional=bidirectional,\n",
    "    num_layers=num_layers,\n",
    "    # value =  None, 'max', 'avg', 'attention', 'multihead_attention'\n",
    "    pooling_method=pooling_method,\n",
    "    num_heads=num_heads,\n",
    "    use_last_hidden=True,\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07752b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction=\"none\"\n",
    "        )\n",
    "        pt = torch.exp(-bce)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        alpha_weight = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n",
    "        focal_loss = alpha_weight * focal_weight * bce\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "# alpha = 1 - data_rnn_origin[\"mro\"].eq(1).mean()\n",
    "alpha = 1 - data_rnn_origin[\"mro\"].eq(1).mean()\n",
    "gamma = 4\n",
    "criterion = FocalLoss(alpha=alpha, gamma=gamma).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f61c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "fieldnames = [\n",
    "    \"Epoch\",\n",
    "    \"Train Loss\",\n",
    "    \"Train F1\",\n",
    "    \"Train Accuracy\",\n",
    "    \"Train Recall\",\n",
    "    \"Train Precision\",\n",
    "    \"Train AUC\",\n",
    "    \"Val Loss\",\n",
    "    \"Val F1\",\n",
    "    \"Val Accuracy\",\n",
    "    \"Val Recall\",\n",
    "    \"Val Precision\",\n",
    "    \"Val AUC\",\n",
    "]\n",
    "\n",
    "log_df = pd.DataFrame(columns=fieldnames)\n",
    "log_df.to_csv(log_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bacf97c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m train_precision = precision_score(all_train_mro_targets, all_train_mro_preds)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_precision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m train_auc = \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_train_mro_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_train_mro_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Validation loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:641\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    639\u001b[39m     labels = np.unique(y_true)\n\u001b[32m    640\u001b[39m     y_true = label_binarize(y_true, classes=labels)[:, \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[32m    650\u001b[39m         partial(_binary_roc_auc_score, max_fpr=max_fpr),\n\u001b[32m    651\u001b[39m         y_true,\n\u001b[32m   (...)\u001b[39m\u001b[32m    654\u001b[39m         sample_weight=sample_weight,\n\u001b[32m    655\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/metrics/_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:388\u001b[39m, in \u001b[36m_binary_roc_auc_score\u001b[39m\u001b[34m(y_true, y_score, sample_weight, max_fpr)\u001b[39m\n\u001b[32m    379\u001b[39m     warnings.warn(\n\u001b[32m    380\u001b[39m         (\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOnly one class is present in y_true. ROC AUC score \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m         UndefinedMetricWarning,\n\u001b[32m    385\u001b[39m     )\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m fpr, tpr, _ = \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr == \u001b[32m1\u001b[39m:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1150\u001b[39m, in \u001b[36mroc_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1047\u001b[39m     {\n\u001b[32m   1048\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1057\u001b[39m     y_true, y_score, *, pos_label=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1058\u001b[39m ):\n\u001b[32m   1059\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[32m   1060\u001b[39m \n\u001b[32m   1061\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m \u001b[33;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[32m   1149\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[32m   1155\u001b[39m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[32m   1156\u001b[39m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[32m   1162\u001b[39m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:841\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    838\u001b[39m y_true = y_true == pos_label\n\u001b[32m    840\u001b[39m \u001b[38;5;66;03m# sort scores and corresponding truth values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m desc_score_indices = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmergesort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[::-\u001b[32m1\u001b[39m]\n\u001b[32m    842\u001b[39m y_score = y_score[desc_score_indices]\n\u001b[32m    843\u001b[39m y_true = y_true[desc_score_indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:1243\u001b[39m, in \u001b[36margsort\u001b[39m\u001b[34m(a, axis, kind, order, stable)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34margsort\u001b[39m(a, axis=-\u001b[32m1\u001b[39m, kind=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, *, stable=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1132\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[33;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[32m   1134\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1241\u001b[39m \n\u001b[32m   1242\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margsort\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstable\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/anaconda3/envs/mro/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    model.train()\n",
    "    all_train_mro_preds = []\n",
    "    all_train_mro_targets = []\n",
    "    all_train_mro_scores = []\n",
    "    for train_inputs, train_targets, train_lengths in train_dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_inputs = train_inputs.to(device)\n",
    "        train_targets = train_targets.to(device)\n",
    "        # train_lengths = train_lengths.to(device)\n",
    "\n",
    "        model_out = model(train_inputs, train_lengths)\n",
    "\n",
    "        loss = criterion(model_out, train_targets[:, -1, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        mro_pred = torch.sigmoid(model_out)\n",
    "        mro_preds = (mro_pred > 0.5).int().cpu().numpy().flatten()\n",
    "        mro_targets = train_targets[:, -1, :].cpu().numpy().flatten()\n",
    "\n",
    "        all_train_mro_preds.extend(mro_preds)\n",
    "        all_train_mro_targets.extend(mro_targets)\n",
    "        all_train_mro_scores.extend(\n",
    "            torch.sigmoid(model_out).detach().cpu().numpy().flatten()\n",
    "        )\n",
    "\n",
    "    average_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss: {average_loss}\")\n",
    "\n",
    "    train_f1 = f1_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training F1 Score: {train_f1}\")\n",
    "    train_accuracy = accuracy_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    train_recall = recall_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Recall: {train_recall}\")\n",
    "    train_precision = precision_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Precision: {train_precision}\")\n",
    "    train_auc = roc_auc_score(all_train_mro_targets, all_train_mro_scores)\n",
    "    print(f\"Training AUC: {train_auc}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_mro_preds = []\n",
    "    all_val_mro_targets = []\n",
    "    all_val_mro_scores = []\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_targets, test_lengths in test_dataloader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_targets = val_targets.to(device)\n",
    "            model_out = model(val_inputs, test_lengths)\n",
    "            loss = criterion(model_out, val_targets[:, -1, :])\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            mro_pred = torch.sigmoid(model_out)\n",
    "            mro_preds = (mro_pred > 0.5).int().cpu().numpy().flatten()\n",
    "            mro_targets = val_targets[:, -1, :].cpu().numpy().flatten()\n",
    "\n",
    "            all_val_mro_preds.extend(mro_preds)\n",
    "            all_val_mro_targets.extend(mro_targets)\n",
    "            all_val_mro_scores.extend(\n",
    "                torch.sigmoid(model_out).detach().cpu().numpy().flatten()\n",
    "            )\n",
    "        average_val_loss = val_loss / len(test_dataloader)\n",
    "        print(f\"Validation Loss: {average_val_loss}\")\n",
    "        val_f1 = f1_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation F1 Score: {val_f1}\")\n",
    "        val_accuracy = accuracy_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "        val_recall = recall_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Recall: {val_recall}\")\n",
    "        val_precision = precision_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Precision: {val_precision}\")\n",
    "        val_auc = roc_auc_score(all_val_mro_targets, all_val_mro_scores)\n",
    "        print(f\"Validation AUC: {val_auc}\")\n",
    "\n",
    "    log_entry = {\n",
    "        \"Epoch\": epoch,\n",
    "        \"Train Loss\": average_loss,\n",
    "        \"Train F1\": train_f1,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train AUC\": train_auc,\n",
    "        \"Val Loss\": average_val_loss,\n",
    "        \"Val F1\": val_f1,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val AUC\": val_auc,\n",
    "    }\n",
    "    entry_df = pd.DataFrame([log_entry])\n",
    "    entry_df.to_csv(log_file_path, mode=\"a\", header=False, index=False)\n",
    "\n",
    "    if best_val_f1 < val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        counter = 0\n",
    "        # save the model\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        # torchscript_model = torch.jit.script(model)\n",
    "        # torchscript_model.save(pt_model_save_path)\n",
    "        best_epoch = epoch\n",
    "        best_log_entry = log_entry\n",
    "\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            print(\"Best Epoch is:\", best_epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27886e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
