{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../weekly_filter_new_3.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer yr/mth/week nbr to time\n",
    "df.loc[(df['mth_nbr'] == 12) & (df['week_nbr'] == 1), 'week_nbr'] = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add NA records for the missing weeks to the original dataset\n",
    "df = df.sort_values(['id', 'yr_nbr', 'mth_nbr', 'week_nbr'])\n",
    "grouped = df.groupby('id')\n",
    "filled_dfs = []\n",
    "for group_name, group_data in grouped:\n",
    "    min_yr_nbr = group_data['yr_nbr'].min()\n",
    "    max_yr_nbr = group_data['yr_nbr'].max()\n",
    "    for yr_nbr in range(min_yr_nbr, max_yr_nbr + 1):\n",
    "        min_week_nbr = group_data[group_data['yr_nbr'] == yr_nbr]['week_nbr'].min()\n",
    "        max_week_nbr = group_data[group_data['yr_nbr'] == yr_nbr]['week_nbr'].max()\n",
    "        expected_weeks = set(range(min_week_nbr, max_week_nbr + 1))\n",
    "        actual_weeks = set(group_data[group_data['yr_nbr'] == yr_nbr]['week_nbr'])\n",
    "        missing_weeks = expected_weeks - actual_weeks\n",
    "        if missing_weeks:\n",
    "            missing_data = [{'id': group_name, 'yr_nbr': yr_nbr, 'week_nbr': week_nbr} for week_nbr in missing_weeks]\n",
    "            filled_dfs.append(pd.DataFrame(missing_data))\n",
    "if filled_dfs:\n",
    "    filled_df = pd.concat(filled_dfs)\n",
    "    df = pd.concat([df, filled_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get date\n",
    "def get_date_from_year_week(year, week):\n",
    "    first_day_of_year = datetime(year, 1, 1)\n",
    "    days_to_add = timedelta(days=(week - 1) * 7)\n",
    "    target_date = first_day_of_year + days_to_add\n",
    "    return target_date\n",
    "df['time'] = df.apply(lambda row: get_date_from_year_week(row['yr_nbr'], row['week_nbr']), axis=1)\n",
    "df = df.drop(['yr_nbr','week_nbr','mth_nbr'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jieyi Zhang\\AppData\\Local\\Temp\\ipykernel_35388\\560541717.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[fill_cols_ffill] = df[fill_cols_ffill].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "#fill NA records\n",
    "fill_cols_zero = ['mro_new', 'hard_braking', 'hard_acceleration', 'speeding_sum', 'day_mileage']\n",
    "df[fill_cols_zero] = df[fill_cols_zero].fillna(0)\n",
    "fill_cols_ffill = ['est_hh_incm_prmr_cd', 'purchaser_age_at_tm_of_purch',\n",
    "                   'input_indiv_gndr_prmr_cd', 'gmqualty_model', 'umf_xref_finc_gbl_trim',\n",
    "                   'engn_size', 'purchase_time', 'tavg', 'random_avg_traffic']\n",
    "df[fill_cols_ffill] = df[fill_cols_ffill].fillna(method='ffill')\n",
    "df = df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode factor variables\n",
    "label_encoder = LabelEncoder()\n",
    "result_df = df[['id', 'mro_new', 'est_hh_incm_prmr_cd', 'purchaser_age_at_tm_of_purch', 'engn_size', 'tavg', 'random_avg_traffic','hard_braking', 'hard_acceleration', 'speeding_sum', 'day_mileage']]\n",
    "result_df['input_indiv_gndr_prmr_cd'] = label_encoder.fit_transform(df['input_indiv_gndr_prmr_cd'])\n",
    "result_df['gmqualty_model'] = label_encoder.fit_transform(df['gmqualty_model'])\n",
    "result_df['umf_xref_finc_gbl_trim'] = label_encoder.fit_transform(df['umf_xref_finc_gbl_trim'])\n",
    "result_df['purchase_time'] = label_encoder.fit_transform(df['purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[f'mro_lag'] = result_df.groupby('id')['mro_new'].transform(lambda x: x.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driving behavior + mro_indicator\n",
    "feature_cols = ['est_hh_incm_prmr_cd', 'input_indiv_gndr_prmr_cd',\n",
    "       'gmqualty_model', 'umf_xref_finc_gbl_trim', 'purchase_time', 'mro_lag','purchaser_age_at_tm_of_purch', 'engn_size', 'tavg',\n",
    "       'random_avg_traffic', 'hard_braking', 'hard_acceleration', 'speeding_sum', 'day_mileage']\n",
    "df = df[['id','mro_new'] + feature_cols]\n",
    "target_col = 'mro_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no driving behavior + mro_indicator\n",
    "feature_cols = ['est_hh_incm_prmr_cd', 'input_indiv_gndr_prmr_cd',\n",
    "       'gmqualty_model', 'umf_xref_finc_gbl_trim', 'purchase_time',\n",
    "       'mro_lag', 'purchaser_age_at_tm_of_purch', 'engn_size', 'tavg',\n",
    "       'random_avg_traffic'\n",
    "]\n",
    "df = df[['id','mro_new'] + feature_cols]\n",
    "target_col = 'mro_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no driving behavior + no mro_indicator\n",
    "feature_cols = ['est_hh_incm_prmr_cd', 'input_indiv_gndr_prmr_cd',\n",
    "       'gmqualty_model', 'umf_xref_finc_gbl_trim', 'purchase_time',\n",
    "       'purchaser_age_at_tm_of_purch', 'engn_size', 'tavg',\n",
    "       'random_avg_traffic'\n",
    "]\n",
    "df = df[['id','mro_new'] + feature_cols]\n",
    "target_col = 'mro_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 58839\n",
      "First sequence features shape: (101, 14)\n",
      "First sequence target shape: (101,)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id, group in df.groupby('id'):\n",
    "    group_features = group[feature_cols].values\n",
    "    group_target = group[target_col].values\n",
    "    data.append((group_features, group_target))\n",
    "print(f\"Total sequences: {len(data)}\")\n",
    "print(f\"First sequence features shape: {data[0][0].shape}\")\n",
    "print(f\"First sequence target shape: {data[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([58839, 103, 14])\n",
      "Targets shape: torch.Size([58839, 103])\n"
     ]
    }
   ],
   "source": [
    "features = [torch.tensor(d[0], dtype=torch.float32) for d in data]\n",
    "targets = [torch.tensor(d[1], dtype=torch.float32) for d in data]\n",
    "\n",
    "features_padded = pad_sequence(features, batch_first=True)\n",
    "targets_padded = pad_sequence(targets, batch_first=True)\n",
    "\n",
    "print(\"Features shape:\", features_padded.shape)\n",
    "print(\"Targets shape:\", targets_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(features, targets, time_window, prediction_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        feature_len = features[i].shape[0]\n",
    "        \n",
    "        # Check if feature length is sufficient\n",
    "        if feature_len < time_window + prediction_length:\n",
    "            raise ValueError(\"Feature length is less than the sum of time_window and prediction_length.\")\n",
    "        \n",
    "        for j in range(feature_len - time_window - prediction_length + 1):\n",
    "            X.append(torch.tensor(features[i][j:j + time_window], dtype=torch.float32))\n",
    "            y.append(torch.tensor(targets[i][j + time_window:j + time_window + prediction_length], dtype=torch.float32))   \n",
    "    return torch.stack(X), torch.stack(y)\n",
    "\n",
    "time_window = 8\n",
    "prediction_length = 1\n",
    "X, y = create_windows(features_padded, targets_padded, time_window, prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 14\n",
    "hidden_size = 128\n",
    "num_layers = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "positive_weight = (train_y == 0).sum().float() / (train_y == 1).sum().float()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=positive_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Permutation Feature Importance. Shuffle a feature column -> calculate test metrics\n",
    "'''\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "test_features_np = test_X.numpy() \n",
    "column_index = 11\n",
    "column_to_shuffle = test_features_np[:, :, column_index]\n",
    "shuffled_indices = np.random.permutation(len(column_to_shuffle))\n",
    "shuffled_column = column_to_shuffle[shuffled_indices]\n",
    "test_features_np[:, :,  column_index] = shuffled_column\n",
    "test_features_tensor = torch.tensor(test_features_np, dtype=torch.float32)\n",
    "test_targets_tensor = test_y\n",
    "test_dataset_new = TensorDataset(test_features_tensor, test_targets_tensor)\n",
    "test_loader_new = DataLoader(test_dataset_new, batch_size=64, shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs).squeeze()\n",
    "        all_targets.extend(targets.cpu().numpy().flatten().tolist())\n",
    "        all_predictions.extend(torch.sigmoid(outputs).cpu().numpy().flatten().tolist())\n",
    "\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "all_predictions = np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.685\n",
    "all_predictions_1 = (all_predictions> threshold).astype(float)\n",
    "\n",
    "# 计算 precision, recall, f1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(all_targets, all_predictions_1, average='binary')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
