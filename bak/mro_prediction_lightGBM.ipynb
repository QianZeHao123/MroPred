{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2month_new1.csv', index_col=0)\n",
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mro_new</th>\n",
       "      <th>est_hh_incm_prmr_cd</th>\n",
       "      <th>purchaser_age_at_tm_of_purch</th>\n",
       "      <th>input_indiv_gndr_prmr_cd</th>\n",
       "      <th>gmqualty_model</th>\n",
       "      <th>umf_xref_finc_gbl_trim</th>\n",
       "      <th>engn_size</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>mro_new_indicator_1</th>\n",
       "      <th>hard_braking_1</th>\n",
       "      <th>hard_acceleration_1</th>\n",
       "      <th>speeding_sum_1</th>\n",
       "      <th>day_mileage_1</th>\n",
       "      <th>tavg_1</th>\n",
       "      <th>random_avg_traffic_1</th>\n",
       "      <th>hard_braking_2</th>\n",
       "      <th>hard_acceleration_2</th>\n",
       "      <th>speeding_sum_2</th>\n",
       "      <th>day_mileage_2</th>\n",
       "      <th>tavg_2</th>\n",
       "      <th>random_avg_traffic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>325.572917</td>\n",
       "      <td>15.110922</td>\n",
       "      <td>0.240708</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>298.156250</td>\n",
       "      <td>15.123979</td>\n",
       "      <td>0.245754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>288.062500</td>\n",
       "      <td>15.106969</td>\n",
       "      <td>0.238053</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>325.572917</td>\n",
       "      <td>15.110922</td>\n",
       "      <td>0.240708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>252.713542</td>\n",
       "      <td>15.050637</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>288.062500</td>\n",
       "      <td>15.106969</td>\n",
       "      <td>0.238053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>507.960935</td>\n",
       "      <td>15.497578</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>252.713542</td>\n",
       "      <td>15.050637</td>\n",
       "      <td>0.233105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>371.135417</td>\n",
       "      <td>15.588944</td>\n",
       "      <td>0.225047</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>507.960935</td>\n",
       "      <td>15.497578</td>\n",
       "      <td>0.227600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mro_new  est_hh_incm_prmr_cd  purchaser_age_at_tm_of_purch  \\\n",
       "2      0.0                  6.0                          54.0   \n",
       "3      0.0                  6.0                          54.0   \n",
       "4      0.0                  6.0                          54.0   \n",
       "5      1.0                  6.0                          54.0   \n",
       "6      0.0                  6.0                          54.0   \n",
       "\n",
       "   input_indiv_gndr_prmr_cd  gmqualty_model  umf_xref_finc_gbl_trim  \\\n",
       "2                         0              13                       0   \n",
       "3                         0              13                       0   \n",
       "4                         0              13                       0   \n",
       "5                         0              13                       0   \n",
       "6                         0              13                       0   \n",
       "\n",
       "   engn_size  purchase_time  mro_new_indicator_1  hard_braking_1  \\\n",
       "2        2.0              0                  0.0       45.666667   \n",
       "3        2.0              0                  0.0       51.333333   \n",
       "4        2.0              0                  0.0       51.666667   \n",
       "5        2.0              0                  0.0       68.500000   \n",
       "6        2.0              0                  1.0       64.333333   \n",
       "\n",
       "   hard_acceleration_1  speeding_sum_1  day_mileage_1     tavg_1  \\\n",
       "2             4.666667       23.666667     325.572917  15.110922   \n",
       "3             7.666667       29.000000     288.062500  15.106969   \n",
       "4            11.000000       28.000000     252.713542  15.050637   \n",
       "5            13.500000       36.500000     507.960935  15.497578   \n",
       "6            10.666667       27.000000     371.135417  15.588944   \n",
       "\n",
       "   random_avg_traffic_1  hard_braking_2  hard_acceleration_2  speeding_sum_2  \\\n",
       "2              0.240708       33.333333             5.666667       19.333333   \n",
       "3              0.238053       45.666667             4.666667       23.666667   \n",
       "4              0.233105       51.333333             7.666667       29.000000   \n",
       "5              0.227600       51.666667            11.000000       28.000000   \n",
       "6              0.225047       68.500000            13.500000       36.500000   \n",
       "\n",
       "   day_mileage_2     tavg_2  random_avg_traffic_2  \n",
       "2     298.156250  15.123979              0.245754  \n",
       "3     325.572917  15.110922              0.240708  \n",
       "4     288.062500  15.106969              0.238053  \n",
       "5     252.713542  15.050637              0.233105  \n",
       "6     507.960935  15.497578              0.227600  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26685"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = pd.read_csv('../id_record_weeks.csv')\n",
    "id_lst = id[(id['record_weeks']>40)&(id['record_weeks']<=70)]['id']\n",
    "            #&(id['record_weeks']<=70)]['id']\n",
    "df_new = df_new[df_new['id'].isin(id_lst)]\n",
    "df_new['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23965"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_1 = pd.read_csv('../weekly_filter_new.csv')\n",
    "id_2018 = list(set(result_df_1[result_df_1['purchase_time'].str[:4] == '2018']['id']))\n",
    "id_2019 = list(set(result_df_1[result_df_1['purchase_time'].str[:4] == '2019']['id']))\n",
    "df_new = df_new[df_new['id'].isin(id_2019)]\n",
    "df_new['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['maintenance'] = df_new.groupby('id')['maintenance'].transform(lambda x: x.shift(1))\n",
    "df_new = df_new.dropna()\n",
    "df_new = df_new.drop('id', axis=1)\n",
    "df_new = df_new.drop(['maintenance_indicator_0', 'maintenance_indicator_2',\n",
    "       'maintenance_indicator_3', 'maintenance_indicator_4',\n",
    "       'maintenance_indicator_5', 'maintenance_indicator_6',\n",
    "       'maintenance_indicator_7'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['repair'] = df_new.groupby('id')['repair'].transform(lambda x: x.shift(1))\n",
    "df_new = df_new.dropna()\n",
    "df_new = df_new.drop('id', axis=1)\n",
    "df_new = df_new.drop(['repair_indicator_0', 'repair_indicator_2', 'repair_indicator_3',\n",
    "       'repair_indicator_4', 'repair_indicator_5', 'repair_indicator_6',\n",
    "       'repair_indicator_7'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new['mro_new']\n",
    "X = df_new.iloc[:, 1:]\n",
    "y = y.astype(int)\n",
    "X = X.astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100,\n",
    "    random_state=12,\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [7, 15, 31]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring=f1_scorer, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 88011, number of negative: 478676\n",
      "[LightGBM] [Info] Total Bins 3082\n",
      "[LightGBM] [Info] Number of data points in the train set: 566687, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20156987625352663, 0.6495634170492394, 0.30766606975356015)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(class_weight = 'balanced', learning_rate = 0.1, n_estimators=100, random_state=42, num_leaves=31, force_col_wise=True) \n",
    "lgbm.fit(X_train, y_train)\n",
    "y_probs = lgbm.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.5\n",
    "pred= (y_probs >= threshold).astype(int)\n",
    "precision = precision_score(np.array(y_test), pred)\n",
    "recall = recall_score(np.array(y_test), pred)\n",
    "f1 = f1_score(np.array(y_test), pred)\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exclude driving behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train[ X_train.columns.drop(list( X_train.filter(regex='hard|speed')))]\n",
    "X_test_2 = X_test[ X_test.columns.drop(list(X_test.filter(regex='hard|speed')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 88011, number of negative: 478676\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 566687, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20049181694406623, 0.6495184084976146, 0.3064036689456028)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(class_weight = 'balanced', learning_rate = 0.1, n_estimators=100, random_state=42, num_leaves=31, force_col_wise=True) \n",
    "lgbm.fit(X_train_2, y_train)\n",
    "y_probs = lgbm.predict_proba(X_test_2)[:, 1]\n",
    "threshold = 0.5\n",
    "pred= (y_probs >= threshold).astype(int)\n",
    "precision = precision_score(np.array(y_test), pred)\n",
    "recall = recall_score(np.array(y_test), pred)\n",
    "f1 = f1_score(np.array(y_test), pred)\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_permutation_importance(\n",
    "    model, X, y, scoring=f1_score, n_repeats=1, random_state=42, average=\"binary\"\n",
    "):\n",
    "    np.random.seed(random_state)\n",
    "    baseline_score = scoring(y, model.predict(X), average=average)\n",
    "    importances = np.zeros(len(X.columns))\n",
    "\n",
    "    feature_groups = [\n",
    "        [\"input_indiv_gndr_prmr_cd\"],\n",
    "        [\"gmqualty_model\"],\n",
    "        [\"umf_xref_finc_gbl_trim\"],\n",
    "        [\"purchase_time\"],\n",
    "        [\"est_hh_incm_prmr_cd\"],\n",
    "        [\"purchaser_age_at_tm_of_purch\"],\n",
    "        [\"engn_size\"],\n",
    "        [\"mro_new_indicator_1\"],\n",
    "        [\n",
    "            \"tavg_0\",\n",
    "            \"tavg_1\",\n",
    "            \"tavg_2\",\n",
    "            \"tavg_3\",\n",
    "            \"tavg_4\",\n",
    "            \"tavg_5\",\n",
    "            \"tavg_6\",\n",
    "            \"tavg_7\",\n",
    "        ],\n",
    "        [\n",
    "            \"random_avg_traffic_0\",\n",
    "            \"random_avg_traffic_1\",\n",
    "            \"random_avg_traffic_2\",\n",
    "            \"random_avg_traffic_3\",\n",
    "            \"random_avg_traffic_4\",\n",
    "            \"random_avg_traffic_5\",\n",
    "            \"random_avg_traffic_6\",\n",
    "            \"random_avg_traffic_7\",\n",
    "        ],\n",
    "        [\n",
    "            \"hard_braking_0\",\n",
    "            \"hard_braking_1\",\n",
    "            \"hard_braking_2\",\n",
    "            \"hard_braking_3\",\n",
    "            \"hard_braking_4\",\n",
    "            \"hard_braking_5\",\n",
    "            \"hard_braking_6\",\n",
    "            \"hard_braking_7\",\n",
    "        ],\n",
    "        [\n",
    "            \"hard_acceleration_0\",\n",
    "            \"hard_acceleration_1\",\n",
    "            \"hard_acceleration_2\",\n",
    "            \"hard_acceleration_3\",\n",
    "            \"hard_acceleration_4\",\n",
    "            \"hard_acceleration_5\",\n",
    "            \"hard_acceleration_6\",\n",
    "            \"hard_acceleration_7\",\n",
    "        ],\n",
    "        [\n",
    "            \"speeding_0\",\n",
    "            \"speeding_1\",\n",
    "            \"speeding_2\",\n",
    "            \"speeding_3\",\n",
    "            \"speeding_4\",\n",
    "            \"speeding_5\",\n",
    "            \"speeding_6\",\n",
    "            \"speeding_7\",\n",
    "        ],\n",
    "        [\n",
    "            \"day_mileage_0\",\n",
    "            \"day_mileage_1\",\n",
    "            \"day_mileage_2\",\n",
    "            \"day_mileage_3\",\n",
    "            \"day_mileage_4\",\n",
    "            \"day_mileage_5\",\n",
    "            \"day_mileage_6\",\n",
    "            \"day_mileage_7\",\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    for group in feature_groups:\n",
    "        group_importance = 0.0\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X.copy()\n",
    "            # 对该组特征的行进行整体 shuffle\n",
    "            shuffled_values = X_permuted[group].sample(frac=1).values\n",
    "            X_permuted[group] = shuffled_values\n",
    "\n",
    "            # 计算模型在打乱特征后的得分\n",
    "            permuted_score = scoring(y, model.predict(X_permuted), average=average)\n",
    "            group_importance += baseline_score - permuted_score\n",
    "\n",
    "        # 取均值作为该组特征的重要性\n",
    "        group_importance /= n_repeats\n",
    "        for col in group:\n",
    "            importances[X.columns.get_loc(col)] = group_importance\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = calculate_permutation_importance(lgbm, X_test, y_test, scoring=f1_score, average='binary')\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else np.arange(X_train.shape[1])\n",
    "fi = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "fi['Importance'] = fi['Importance'] / fi['Importance'].sum()\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
