{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcb19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import preprocess_data_lgbm as preprocess_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.train import  CheckpointConfig, RunConfig, ScalingConfig\n",
    "from ray.train.lightgbm import LightGBMTrainer\n",
    "from utils import create_train_test_group\n",
    "# set GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3, 4, 5, 6, 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bf9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control parameter: data preparation\n",
    "csv_file_name = \"./Data/mro_daily_clean.csv\"\n",
    "target_mro = [\"mro\"]\n",
    "maintain_repair_mro = \"full\"\n",
    "\n",
    "add_mro_prev = True\n",
    "add_purchase_time = True\n",
    "add_driver_behavior = True\n",
    "agg_weeks = 1\n",
    "agg_fun = [\"mean\", \"sum\", \"max\", \"min\", \"std\", \"skew\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b399e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset ./Data/mro_daily_clean.csv successfully.\n",
      "The MRO choosen is: ['mro']\n",
      "No need to know the maintenance or repair.\n",
      "Use the Target MRO.\n",
      "Add Purchase Time: True\n",
      "Add behavior of Driver: True\n",
      "Aggregate the data into 1 week.\n",
      "Add Previous MRO: True\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(\n",
    "    file_name=csv_file_name,\n",
    "    target_mro=target_mro,\n",
    "    maintain_repair_mro=maintain_repair_mro,\n",
    "    add_mro_prev=add_mro_prev,\n",
    "    add_purchase_time=add_purchase_time,\n",
    "    add_driver_behavior=add_driver_behavior,\n",
    "    agg_weeks=agg_weeks,\n",
    "    agg_fun=agg_fun,\n",
    "    time_window = 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531d20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lgbm = create_train_test_group(\n",
    "    data=data,\n",
    "    sample_frac=1.0,\n",
    "    test_size=0.1,\n",
    "    valid_size=0.1,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b22bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lgbm.to_parquet(\"./Data/data_lgbm.gzip\", compression=\"gzip\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3af25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lgbm = pd.read_parquet('./Data/data_lgbm.gzip')\n",
    "# data_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data: pd.DataFrame):\n",
    "    \"\"\"Load and split the dataset into train, validation, and test sets.\"\"\"\n",
    "\n",
    "    train_dataset = data[data[\"group\"] == \"train\"]\n",
    "    valid_dataset = data[data[\"group\"] == \"valid\"]\n",
    "    test_dataset = data[data[\"group\"] == \"test\"]\n",
    "    # train_dataset = train_dataset.drop([\"group\", \"id\", \"mro_prev\"], axis=1)\n",
    "    # valid_dataset = valid_dataset.drop([\"group\", \"id\", \"mro_prev\"], axis=1)\n",
    "    # test_dataset = test_dataset.drop([\"group\", \"id\", \"mro_prev\"], axis=1)\n",
    "    train_dataset = train_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "    valid_dataset = valid_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "    test_dataset = test_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afa611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:56:41,282\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(LightGBMTrainer pid=2370263)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(LightGBMTrainer pid=2370263)\u001b[0m - (node_id=daa43a78680ec46f01f27bf939cc9db6d30bbd142c355a84aff54580, ip=144.214.55.187, pid=2370384) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(LightGBMTrainer pid=2370263)\u001b[0m - (node_id=daa43a78680ec46f01f27bf939cc9db6d30bbd142c355a84aff54580, ip=144.214.55.187, pid=2370382) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(LightGBMTrainer pid=2370263)\u001b[0m - (node_id=daa43a78680ec46f01f27bf939cc9db6d30bbd142c355a84aff54580, ip=144.214.55.187, pid=2370383) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(LightGBMTrainer pid=2370263)\u001b[0m - (node_id=daa43a78680ec46f01f27bf939cc9db6d30bbd142c355a84aff54580, ip=144.214.55.187, pid=2370385) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m Registered dataset logger for dataset dataset_4_0\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Starting execution of Dataset train_2_0. Full logs are in /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Execution plan of Dataset train_2_0: InputDataBuffer[Input] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m ✔️  Dataset train_2_0 execution finished in 0.03 seconds\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m StreamSplitDataIterator(epoch=-1, split=0) blocked waiting on other clients for more than 30s. All clients must read from the DataIterator splits at the same time. This warning will not be printed again for this epoch.\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m Registered dataset logger for dataset dataset_6_0\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370385)\u001b[0m Registered dataset logger for dataset dataset_8_0\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m Registered dataset logger for dataset dataset_11_0\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m Starting execution of Dataset valid_3_0. Full logs are in /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m Execution plan of Dataset valid_3_0: InputDataBuffer[Input] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m ✔️  Dataset valid_3_0 execution finished in 0.03 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Info] Trying to bind port 54223...\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Info] Binding port 54223 succeeded\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 200 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Info] Listening...\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 260 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 338 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 439 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 570 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 741 milliseconds\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Connected to rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Connected to rank 1\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Connected to rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Local rank: 2, total number of machines: 4\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Number of positive: 150915, number of negative: 3019729\n",
      "\u001b[36m(RayTrainWorker pid=2370385)\u001b[0m [LightGBM] [Info] Trying to bind port 56457...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370385)\u001b[0m [LightGBM] [Info] Binding port 56457 succeeded\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Warning] Connecting to rank 3 failed, waiting for 338 milliseconds\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370385)\u001b[0m [LightGBM] [Info] Listening...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Connected to rank 3\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Local rank: 1, total number of machines: 4\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.069433 seconds.\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Total Bins 56794\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 792661, number of used features: 296\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047598 -> initscore=-2.996206\n",
      "\u001b[36m(RayTrainWorker pid=2370383)\u001b[0m [LightGBM] [Info] Start training from score -2.996206\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Number of positive: 150915, number of negative: 3019729\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/user14/ray_results/LightGBMTrainer_2025-06-05_18-56-46/LightGBMTrainer_c604d_00000_0_2025-06-05_18-56-46/checkpoint_000000)\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m Registered dataset logger for dataset valid_3_0\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m [LightGBM] [Info] Finished linking network in 0.359163 seconds\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.325641 seconds.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Total Bins 56794\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 792661, number of used features: 296\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047598 -> initscore=-2.996206\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=2370382)\u001b[0m [LightGBM] [Info] Start training from score -2.996206\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2370384)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/user14/ray_results/LightGBMTrainer_2025-06-05_18-56-46/LightGBMTrainer_c604d_00000_0_2025-06-05_18-56-46/checkpoint_000001)\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Fatal Python error: PyGILState_Release: auto-releasing thread-state, but no thread-state for this thread\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Python runtime state: initialized\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m \n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Thread 0x00007f86af672700 (most recent call first):\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m   <no Python frame>\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m \n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m Thread 0x00007fb6328a0740 (most recent call first):\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m   File \"/home/user14/data/anaconda3/envs/mro/lib/python3.11/site-packages/ray/_private/worker.py\", line 946 in main_loop\n",
      "\u001b[36m(SplitCoordinator pid=2370664)\u001b[0m   File \"/home/user14/data/anaconda3/envs/mro/lib/python3.11/site-packages/ray/_private/workers/default_worker.py\", line 330 in <module>\n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m \n",
      "\u001b[36m(SplitCoordinator pid=2370663)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffc613e55ff7f8537640db982101000000 Worker ID: 09d590c63a2a80dc5cfe604768b6ed76dc3b982ea2ee5ecce42bf099 Node ID: daa43a78680ec46f01f27bf939cc9db6d30bbd142c355a84aff54580 Worker IP address: 144.214.55.187 Worker port: 33117 Worker PID: 2370664 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset = prepare_data(data_lgbm)\n",
    "ray_train_dataset = ray.data.from_pandas(train_dataset)\n",
    "ray_valid_dataset = ray.data.from_pandas(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e66cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:56:46,325\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-05 18:56:46 (running for 00:00:00.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:56:51 (running for 00:00:05.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c662fb4eeb3c4df48394155f705f36f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=2370664) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d27d7efb1847ec9922031fee24cd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=2370664) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-05 18:56:56 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:01 (running for 00:00:15.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:06 (running for 00:00:20.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:11 (running for 00:00:25.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:16 (running for 00:00:30.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:21 (running for 00:00:35.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:26 (running for 00:00:40.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:31 (running for 00:00:45.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:36 (running for 00:00:50.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:41 (running for 00:00:55.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:46 (running for 00:01:00.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:51 (running for 00:01:05.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1373d6ea21ec4926b6050d45abf24603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=2370663) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a124d085493e470ea106bfa26d1d9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=2370663) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-05 18:57:56 (running for 00:01:10.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:02 (running for 00:01:15.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:07 (running for 00:01:20.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:12 (running for 00:01:25.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:17 (running for 00:01:30.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:22 (running for 00:01:35.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:27 (running for 00:01:40.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:32 (running for 00:01:45.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:37 (running for 00:01:50.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:42 (running for 00:01:55.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:47 (running for 00:02:01.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:52 (running for 00:02:06.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:58:57 (running for 00:02:11.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:59:02 (running for 00:02:16.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-05 18:59:07 (running for 00:02:21.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:59:08,333\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/user14/ray_results/LightGBMTrainer_2025-06-05_18-56-46' in 0.0035s.\n",
      "2025-06-05 18:59:08,336\tINFO tune.py:1041 -- Total run time: 142.01 seconds (141.98 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-05 18:59:08 (running for 00:02:21.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/40 CPUs, 4.0/6 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-05_18-56-35_222224_2367005/artifacts/2025-06-05_18-56-46/LightGBMTrainer_2025-06-05_18-56-46/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure checkpointing to save progress during training\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        # Checkpoint every 10 iterations.\n",
    "        checkpoint_frequency=10,\n",
    "        # Only keep the latest checkpoint and delete the others.\n",
    "        num_to_keep=20,\n",
    "    )\n",
    ")\n",
    "# Set up the XGBoost trainer with the specified configuration\n",
    "trainer = LightGBMTrainer(\n",
    "    # see \"How to scale out training?\" for more details\n",
    "    scaling_config=ScalingConfig(\n",
    "        # Number of workers to use for data parallelism.\n",
    "        num_workers=4,\n",
    "        # Whether to use GPU acceleration. Set to True to schedule GPU workers.\n",
    "        use_gpu=True,\n",
    "    ),\n",
    "    label_column=\"target_mro\",\n",
    "    num_boost_round=20,\n",
    "    # XGBoost specific params (see the `xgboost.train` API reference)\n",
    "    params={\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"binary_logloss\", \"binary_error\", \"auc\", \"average_precision\"],\n",
    "        # \"device\": \"gpu\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"max_depth\": 8,\n",
    "        \"is_unbalance\": True,\n",
    "    },\n",
    "    datasets={\"train\": ray_train_dataset, \"valid\": ray_valid_dataset},\n",
    "    # store the preprocessor in the checkpoint for inference later\n",
    "    run_config=run_config,\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89da3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = \"./output/lgbm\"\n",
    "model_path = os.path.join(output_dir, \"model_lgbm.txt\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1143d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = trainer.get_model(result.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd05450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f1ad9157290>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80967ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Test Set:\n",
      "Accuracy:  0.9427\n",
      "Precision: 0.1905\n",
      "Recall:    0.0629\n",
      "F1 Score:  0.0946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "def get_X_y(df):\n",
    "    X = df.drop(\"target_mro\",  axis=1)\n",
    "    y = df[\"target_mro\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = get_X_y(train_dataset)\n",
    "X_valid, y_valid = get_X_y(valid_dataset)\n",
    "X_test, y_test = get_X_y(test_dataset)\n",
    "\n",
    "\n",
    "def predict_and_eval(booster, X, y_true, dataset_name=\"dataset\"):\n",
    "    y_prob = booster.predict(X)\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\nEvaluation on {dataset_name}:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        {\"y_true\": y_true.values, \"y_prob\": y_prob, \"y_pred\": y_pred}\n",
    "    )\n",
    "\n",
    "    return acc, precision, recall, f1, result_df\n",
    "\n",
    "\n",
    "# predict_and_eval(booster, X_train, y_train, \"Train Set\")\n",
    "# predict_and_eval(booster, X_valid, y_valid, \"Validation Set\")\n",
    "# predict_and_eval(booster, X_test, y_test, \"Test Set\")\n",
    "acc, precision, recall, f1, df_result = predict_and_eval(\n",
    "    booster, X_test, y_test, \"Test Set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2bc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
