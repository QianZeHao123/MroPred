{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba21208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import preprocess_data_lgbm as preprocess_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.train import CheckpointConfig, RunConfig, ScalingConfig\n",
    "from ray.train.lightgbm import LightGBMTrainer\n",
    "from utils import create_train_test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715db682",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"./Data/mro_daily_clean.csv\"\n",
    "target_mro = [\"mro\"]\n",
    "\n",
    "maintain_repair_mro = \"full\"\n",
    "\n",
    "add_mro_prev = True\n",
    "add_purchase_time = True\n",
    "add_driver_behavior = True\n",
    "agg_weeks = 1\n",
    "agg_fun = [\"mean\", \"sum\", \"max\", \"min\", \"std\", \"skew\"]\n",
    "# time window could be 4, 8, 12\n",
    "time_window = 8\n",
    "\n",
    "# ------------------------------------------\n",
    "# LightGBM Parameters\n",
    "metric: list = [\"binary_logloss\", \"binary_error\", \"auc\", \"average_precision\"]\n",
    "learning_rate: float = 0.05\n",
    "num_leaves: int = 64\n",
    "max_depth: int = 8\n",
    "is_unbalance: bool = True\n",
    "# boosting could be \"gbdt\", \"rf\" (random forest) and \"dart\"\n",
    "boosting: str = \"gbdt\"\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# data record folder\n",
    "data_lgbm_file_name = f\"data_lgbm_db{int(add_driver_behavior)}_mp{int(add_mro_prev)}_pt{int(add_purchase_time)}_aw{agg_weeks}_tw{time_window}.gzip\"\n",
    "data_lgbm_path = os.path.join(\"./Data\", data_lgbm_file_name)\n",
    "data_lgbm_path = os.path.abspath(data_lgbm_path)\n",
    "\n",
    "# ------------------------------------------\n",
    "# model record folder\n",
    "model_name = f\"model_lgbm_{boosting}_db{int(add_driver_behavior)}_mp{int(add_mro_prev)}_pt{int(add_purchase_time)}_aw{agg_weeks}_tw{time_window}.json\"\n",
    "model_output_dir = \"./output/lgbm\"\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_output_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2636bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(data_lgbm_path):\n",
    "    print(f\"Data file {data_lgbm_path} exists.\")\n",
    "    data_lgbm = pd.read_parquet(data_lgbm_path)\n",
    "else:\n",
    "    print(f\"{data_lgbm_path} does not exist.\")\n",
    "    # control parameter: data preparation\n",
    "    data = preprocess_data(\n",
    "        file_name=csv_file_name,\n",
    "        target_mro=target_mro,\n",
    "        maintain_repair_mro=maintain_repair_mro,\n",
    "        add_mro_prev=add_mro_prev,\n",
    "        add_purchase_time=add_purchase_time,\n",
    "        add_driver_behavior=add_driver_behavior,\n",
    "        agg_weeks=agg_weeks,\n",
    "        agg_fun=agg_fun,\n",
    "        time_window=time_window,\n",
    "    )\n",
    "\n",
    "    data_lgbm = create_train_test_group(\n",
    "        data=data,\n",
    "        sample_frac=1.0,\n",
    "        test_size=0.1,\n",
    "        valid_size=0.1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    data_lgbm.to_parquet(data_lgbm_path, compression=\"gzip\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb220a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data: pd.DataFrame):\n",
    "    \"\"\"Load and split the dataset into train, validation, and test sets.\"\"\"\n",
    "\n",
    "    train_dataset = data[data[\"group\"] == \"train\"]\n",
    "    valid_dataset = data[data[\"group\"] == \"valid\"]\n",
    "    test_dataset = data[data[\"group\"] == \"test\"]\n",
    "\n",
    "    train_dataset = train_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "    valid_dataset = valid_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "    test_dataset = test_dataset.drop([\"group\", \"id\"], axis=1)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12082efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = prepare_data(data_lgbm)\n",
    "ray_train_dataset = ray.data.from_pandas(train_dataset)\n",
    "ray_valid_dataset = ray.data.from_pandas(valid_dataset)\n",
    "\n",
    "\n",
    "# Configure checkpointing to save progress during training\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        # Checkpoint every 10 iterations.\n",
    "        checkpoint_frequency=10,\n",
    "        # Only keep the latest checkpoint and delete the others.\n",
    "        num_to_keep=20,\n",
    "    )\n",
    ")\n",
    "# Set up the XGBoost trainer with the specified configuration\n",
    "trainer = LightGBMTrainer(\n",
    "    # see \"How to scale out training?\" for more details\n",
    "    scaling_config=ScalingConfig(\n",
    "        # Number of workers to use for data parallelism.\n",
    "        num_workers=4,\n",
    "        # Whether to use GPU acceleration. Set to True to schedule GPU workers.\n",
    "        use_gpu=True,\n",
    "    ),\n",
    "    label_column=\"target_mro\",\n",
    "    num_boost_round=20,\n",
    "    # XGBoost specific params (see the `xgboost.train` API reference)\n",
    "    params={\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": metric,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"is_unbalance\": is_unbalance,\n",
    "        \"boosting\": boosting,\n",
    "        \"device_type\": \"gpu\",\n",
    "    },\n",
    "    datasets={\"train\": ray_train_dataset, \"valid\": ray_valid_dataset},\n",
    "    # store the preprocessor in the checkpoint for inference later\n",
    "    run_config=run_config,\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "booster = trainer.get_model(result.checkpoint)\n",
    "json_model = booster.dump_model()\n",
    "\n",
    "model_json_file = open(model_path, 'w')\n",
    "try:\n",
    "    json.dump(json_model, model_json_file, indent=4)\n",
    "finally:\n",
    "    model_json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "def get_X_y(df):\n",
    "    X = df.drop(\"target_mro\", axis=1)\n",
    "    y = df[\"target_mro\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = get_X_y(train_dataset)\n",
    "X_valid, y_valid = get_X_y(valid_dataset)\n",
    "X_test, y_test = get_X_y(test_dataset)\n",
    "\n",
    "\n",
    "def predict_and_eval(booster, X, y_true, dataset_name=\"dataset\"):\n",
    "    y_prob = booster.predict(X)\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\nEvaluation on {dataset_name}:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        {\"y_true\": y_true.values, \"y_prob\": y_prob, \"y_pred\": y_pred}\n",
    "    )\n",
    "\n",
    "    return acc, precision, recall, f1, result_df\n",
    "\n",
    "\n",
    "# predict_and_eval(booster, X_train, y_train, \"Train Set\")\n",
    "# predict_and_eval(booster, X_valid, y_valid, \"Validation Set\")\n",
    "# predict_and_eval(booster, X_test, y_test, \"Test Set\")\n",
    "acc, precision, recall, f1, df_result = predict_and_eval(\n",
    "    booster, X_test, y_test, \"Test Set\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
