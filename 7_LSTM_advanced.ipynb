{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5958af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frac = 0.01\n",
    "test_size = 0.1\n",
    "max_seq_length = 50\n",
    "batch_size = 4096\n",
    "num_workers = 16\n",
    "rnn_output_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = float(\"inf\")\n",
    "counter = 0\n",
    "patience = 10\n",
    "\n",
    "time_window_leakage = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ad5db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices available: 10\n",
      "Using device: NVIDIA GeForce RTX 2080 Ti\n",
      "Using cuda:8 device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils import create_train_test_group\n",
    "\n",
    "# update mroRnnDataset with better performance\n",
    "from utils import mroRnnDatasetNew as mroRnnDataset\n",
    "from utils import collate_fn\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices available: {num_gpus}\")\n",
    "    # Select a specific GPU (e.g., GPU 0)\n",
    "    device = torch.device(\"cuda:8\")  # Use \"cuda:1\" for GPU 1, etc.\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA is not available, using CPU\")\n",
    "\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bfc9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Data/mro_daily_clean.csv\"\n",
    "data = pd.read_csv(file_name, index_col=0, engine=\"pyarrow\")\n",
    "\n",
    "\n",
    "column_need_std = [\n",
    "    \"hard_braking\",\n",
    "    \"hard_acceleration\",\n",
    "    \"speeding_sum\",\n",
    "    \"day_mileage\",\n",
    "    \"engn_size\",\n",
    "    \"est_hh_incm_prmr_cd\",\n",
    "    \"purchaser_age_at_tm_of_purch\",\n",
    "    \"tavg\",\n",
    "    \"random_avg_traffic\",\n",
    "]\n",
    "\n",
    "column_after_std = [\n",
    "    \"hard_braking_std\",\n",
    "    \"hard_acceleration_std\",\n",
    "    \"speeding_sum_std\",\n",
    "    \"day_mileage_std\",\n",
    "    \"engn_size_std\",\n",
    "    \"est_hh_incm_prmr_cd_std\",\n",
    "    \"purchaser_age_at_tm_of_purch_std\",\n",
    "    \"tavg_std\",\n",
    "    \"random_avg_traffic_std\",\n",
    "]\n",
    "\n",
    "column_need_encode = [\n",
    "    \"gmqualty_model\",\n",
    "    \"umf_xref_finc_gbl_trim\",\n",
    "    \"input_indiv_gndr_prmr_cd\",\n",
    "]\n",
    "\n",
    "column_after_encode = [\n",
    "    \"gmqualty_model_encode\",\n",
    "    \"umf_xref_finc_gbl_trim_encode\",\n",
    "    \"input_indiv_gndr_prmr_cd_encode\",\n",
    "]\n",
    "\n",
    "column_after_encode_std = [\n",
    "    \"gmqualty_model_encode_std\",\n",
    "    \"umf_xref_finc_gbl_trim_encode_std\",\n",
    "    \"input_indiv_gndr_prmr_cd_encode_std\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64ee9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "data[column_after_std] = scaler.fit_transform(data[column_need_std])\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical = encoder.fit_transform(data[column_need_encode])\n",
    "\n",
    "category_counts = [\n",
    "    len(encoder.categories_[i]) for i, _ in enumerate(column_need_encode)\n",
    "]\n",
    "\n",
    "onehot_feature_names = []\n",
    "for col_idx, col in enumerate(column_need_encode):\n",
    "    num_categories = category_counts[col_idx]\n",
    "    onehot_feature_names.extend([f\"{col}_onehot_{i}\" for i in range(num_categories)])\n",
    "\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_categorical, index=data.index, columns=onehot_feature_names\n",
    ")\n",
    "data = pd.concat([data, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73dec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_features = column_after_std + onehot_feature_names\n",
    "col_rnn_origin = [\"id\"] + rnn_features + [\"mro\"]\n",
    "data_rnn_origin = data[\n",
    "    col_rnn_origin\n",
    "].copy()\n",
    "data_rnn_origin = create_train_test_group(\n",
    "    data_rnn_origin, sample_frac=sample_frac, test_size=test_size\n",
    ")\n",
    "rnn_target = [\"mro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b59696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_leakage_all_events(\n",
    "#     df: pd.DataFrame,\n",
    "#     id_col=\"id\",\n",
    "#     target_col=\"mro\",\n",
    "#     window_size=5,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     For each time series of IDs, find all positions where MRO=1,\n",
    "#     mark the MRO of each time step before each MRO=1 as 1.\n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "\n",
    "#     def process_group(group: pd.DataFrame):\n",
    "#         # find all the index when MRO=1\n",
    "#         one_indices = group[group[target_col] == 1].index.tolist()\n",
    "#         if not one_indices:  # if no 1 in the seq, return origin seq\n",
    "#             return group\n",
    "\n",
    "#         for first_one_idx in one_indices:\n",
    "#             start_idx = max(group.index.min(), first_one_idx - window_size)\n",
    "#             group.loc[start_idx:first_one_idx, target_col] = 1\n",
    "#         return group\n",
    "\n",
    "#     df = df.groupby(id_col,group_keys=False).apply(process_group).reset_index(drop=True)\n",
    "#     # df = df.groupby(id_col).apply(lambda g: process_group(g.drop(columns=[id_col]))).reset_index()\n",
    "#     return df\n",
    "\n",
    "\n",
    "def label_leakage_all_events(\n",
    "    df: pd.DataFrame,\n",
    "    id_col=\"id\",\n",
    "    target_col=\"mro\",\n",
    "    window_size=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each time series of IDs, find all positions where MRO=1,\n",
    "    mark the MRO of each time step before each MRO=1 as 1.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def process_group(group: pd.DataFrame):\n",
    "        # find all the index when MRO=1\n",
    "        one_indices = group[group[target_col] == 1].index.tolist()\n",
    "        if not one_indices:  # if no 1 in the seq, return origin seq\n",
    "            return group\n",
    "\n",
    "        for first_one_idx in one_indices:\n",
    "            start_idx = max(group.index.min(), first_one_idx - window_size)\n",
    "            group.loc[start_idx:first_one_idx, target_col] = 1\n",
    "        return group\n",
    "\n",
    "    # Step 1: Remove id_col from dataframe before groupby\n",
    "    original_id = df[id_col]\n",
    "    data_to_process = df.drop(columns=[id_col])\n",
    "\n",
    "    # Step 2: Group and apply function on reduced dataframe\n",
    "    processed_data = (\n",
    "        data_to_process.groupby(original_id, group_keys=False)\n",
    "        .apply(process_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Step 3: Re-add the id column back\n",
    "    processed_data[id_col] = original_id.reset_index(drop=True)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "data_rnn_origin = label_leakage_all_events(\n",
    "    data_rnn_origin,\n",
    "    id_col=\"id\",\n",
    "    target_col=\"mro\",\n",
    "    window_size=time_window_leakage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = mroRnnDataset(\n",
    "    data_rnn_origin=data_rnn_origin,\n",
    "    rnn_features=rnn_features,\n",
    "    rnn_target=rnn_target,\n",
    "    group=\"train\",\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "test_data_set = mroRnnDataset(\n",
    "    data_rnn_origin=data_rnn_origin,\n",
    "    rnn_features=rnn_features,\n",
    "    rnn_target=rnn_target,\n",
    "    group=\"test\",\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "\n",
    "# Example batch size\n",
    "train_dataloader = DataLoader(\n",
    "    train_data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e22ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type: str,\n",
    "        input_size,\n",
    "        rnn_output_size,\n",
    "        output_size,\n",
    "    ):\n",
    "        super(RnnModel, self).__init__()\n",
    "        if rnn_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=input_size,\n",
    "                hidden_size=rnn_output_size,\n",
    "                num_layers=3,\n",
    "                batch_first=True,\n",
    "                bidirectional=True,\n",
    "                dropout=0.5,\n",
    "            )\n",
    "        # self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(rnn_output_size * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, output_size),\n",
    "        )\n",
    "        # self.fc = nn.Linear(rnn_output_size, output_size)\n",
    "\n",
    "    def forward(self, x, length: torch.Tensor):\n",
    "        # x  (batch_size, seq_len, input_size)\n",
    "        # use pack_padded_sequence and pad_packed_sequence to deal with different length of x input\n",
    "        packed_x = pack_padded_sequence(\n",
    "            x, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, _ = self.rnn(packed_x)\n",
    "        rnn_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        pooled = self.pool(rnn_out.transpose(1, 2)).squeeze(2)\n",
    "        # model_out = self.fc(rnn_out)  # (batch_size, seq_len, output_size)\n",
    "        model_out = self.fc(pooled)  # (batch_size, output_size)\n",
    "        return model_out\n",
    "\n",
    "\n",
    "input_feature_size = len(rnn_features)\n",
    "output_size = len(rnn_target)\n",
    "\n",
    "model = RnnModel(\n",
    "    rnn_type=\"LSTM\",\n",
    "    input_size=input_feature_size,\n",
    "    rnn_output_size=rnn_output_size,\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b393013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_weight_value = (data_rnn_origin[\"mro\"] == 0).sum() / (\n",
    "#     data_rnn_origin[\"mro\"] == 1\n",
    "# ).sum()\n",
    "pos_weight_value = (data_rnn_origin[\"mro\"] == 0).sum() / (data_rnn_origin[\"mro\"] == 1).sum()\n",
    "print(f\"pos_weight: {pos_weight_value}\")\n",
    "\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value])).to(device)\n",
    "\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=1, gamma=2):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "#         pt = torch.exp(-bce_loss)\n",
    "#         focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "#         return focal_loss.mean()\n",
    "    \n",
    "# alpha = 1 / (1 + pos_weight_value)\n",
    "# alpha = 0.99\n",
    "# criterion = FocalLoss(alpha=alpha, gamma=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# for input, target, length in train_dataloader:\n",
    "#     target: torch.Tensor\n",
    "#     input: torch.Tensor\n",
    "#     print(input.shape)\n",
    "#     print(target.shape)\n",
    "#     print(length)\n",
    "#     break\n",
    "\n",
    "\n",
    "log_dir = \"Out\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file_path = os.path.join(log_dir, f\"training_log_{timestamp}.csv\")\n",
    "\n",
    "pt_model_dir = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(pt_model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "model_save_path = os.path.join(pt_model_dir, f\"best_model_{timestamp}.pth\")\n",
    "pt_model_save_path = os.path.join(pt_model_dir, f\"best_model_{timestamp}.pt\")\n",
    "\n",
    "fieldnames = [\n",
    "    \"Epoch\",\n",
    "    \"Train Loss\",\n",
    "    \"Train F1\",\n",
    "    \"Train Accuracy\",\n",
    "    \"Train Recall\",\n",
    "    \"Train Precision\",\n",
    "    \"Val Loss\",\n",
    "    \"Val F1\",\n",
    "    \"Val Accuracy\",\n",
    "    \"Val Recall\",\n",
    "    \"Val Precision\",\n",
    "]\n",
    "\n",
    "log_df = pd.DataFrame(columns=fieldnames)\n",
    "log_df.to_csv(log_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    model.train()\n",
    "    all_train_mro_preds = []\n",
    "    all_train_mro_targets = []\n",
    "    for train_inputs, train_targets, train_lengths in train_dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_inputs = train_inputs.to(device)\n",
    "        train_targets = train_targets.to(device)\n",
    "        # train_lengths = train_lengths.to(device)\n",
    "\n",
    "        model_out = model(train_inputs, train_lengths)\n",
    "\n",
    "        loss = criterion(model_out, train_targets[:, -1, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        mro_pred = torch.sigmoid(model_out)\n",
    "        mro_preds = (mro_pred > 0.5).int().cpu().numpy().flatten()\n",
    "        mro_targets = train_targets[:, -1, :].cpu().numpy().flatten()\n",
    "\n",
    "        all_train_mro_preds.extend(mro_preds)\n",
    "        all_train_mro_targets.extend(mro_targets)\n",
    "\n",
    "    average_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss: {average_loss}\")\n",
    "\n",
    "    train_f1 = f1_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training F1 Score: {train_f1}\")\n",
    "    train_accuracy = accuracy_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    train_recall = recall_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Recall: {train_recall}\")\n",
    "    train_precision = precision_score(all_train_mro_targets, all_train_mro_preds)\n",
    "    print(f\"Training Precision: {train_precision}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_mro_preds = []\n",
    "    all_val_mro_targets = []\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_targets, test_lengths in test_dataloader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_targets = val_targets.to(device)\n",
    "            model_out = model(val_inputs, test_lengths)\n",
    "            loss = criterion(model_out, val_targets[:, -1, :])\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            mro_pred = torch.sigmoid(model_out)\n",
    "            mro_preds = (mro_pred > 0.5).int().cpu().numpy().flatten()\n",
    "            mro_targets = val_targets[:, -1, :].cpu().numpy().flatten()\n",
    "\n",
    "            all_val_mro_preds.extend(mro_preds)\n",
    "            all_val_mro_targets.extend(mro_targets)\n",
    "\n",
    "        average_val_loss = val_loss / len(test_dataloader)\n",
    "        print(f\"Validation Loss: {average_val_loss}\")\n",
    "        val_f1 = f1_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation F1 Score: {val_f1}\")\n",
    "        val_accuracy = accuracy_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "        val_recall = recall_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Recall: {val_recall}\")\n",
    "        val_precision = precision_score(all_val_mro_targets, all_val_mro_preds)\n",
    "        print(f\"Validation Precision: {val_precision}\")\n",
    "\n",
    "    log_entry = {\n",
    "        \"Epoch\": epoch,\n",
    "        \"Train Loss\": average_loss,\n",
    "        \"Train F1\": train_f1,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Val Loss\": average_val_loss,\n",
    "        \"Val F1\": val_f1,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val Precision\": val_precision,\n",
    "    }\n",
    "    entry_df = pd.DataFrame([log_entry])\n",
    "    entry_df.to_csv(log_file_path, mode=\"a\", header=False, index=False)\n",
    "\n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        counter = 0\n",
    "        # save the model\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        torchscript_model = torch.jit.script(model)\n",
    "        torchscript_model.save(pt_model_save_path)\n",
    "        best_epoch = epoch\n",
    "\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            print(\"Best Epoch is:\", best_epoch)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b393013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
